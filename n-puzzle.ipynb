{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, state: np.ndarray):\n",
    "        self.state: np.ndarray = state\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.state.tobytes().__hash__()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, State):\n",
    "            return np.array_equal(self.state, other.state)\n",
    "        return self.state == other\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return True\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.state[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.state[key] = value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.state.ravel())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state.ravel())\n",
    "        \n",
    "    def copy(self):\n",
    "        return State(self.state.copy())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_from_state(state: np.ndarray) -> tuple:\n",
    "    x, y = [int(i[0]) for i in np.where(state == 0)]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = zero_from_state(state)\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: State, action: 'Action') -> State:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMIZE_STEPS = 10\n",
    "# state = np.random.choice(range(PUZZLE_DIM**2), (PUZZLE_DIM, PUZZLE_DIM), replace=False)\n",
    "# goal = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "# for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "#     state = do_action(state, choice(available_actions(state)))\n",
    "#     print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breath-First Search (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bfs(state: State, goal: np.ndarray):\n",
    "#     path = list()\n",
    "#     queue = list()\n",
    "#     visited = set()\n",
    "#     # Append first element to queue\n",
    "#     queue.append(state)\n",
    "#     visited.add(state)\n",
    "    \n",
    "#     while queue:\n",
    "#         current_state = queue.pop(0)\n",
    "#         actions = available_actions(current_state)\n",
    "        \n",
    "#         print(current_state)\n",
    "        \n",
    "#         # Check for goal reached\n",
    "#         if np.array_equal(current_state, goal):\n",
    "#             return True, path\n",
    "        \n",
    "#         # Iterate over all possible actions\n",
    "#         for action in actions:\n",
    "#             new_state = do_action(current_state, action)\n",
    "#             # Expand only if next state is not visited\n",
    "#             if new_state not in visited:\n",
    "#                 queue.append(new_state)\n",
    "#                 visited.add(new_state)\n",
    "#                 path.append(new_state)\n",
    "    \n",
    "#     return False, path\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_pos(state_game: np.ndarray, n: int) -> tuple[int, int]:\n",
    "    x, y = [int(i[0]) for i in np.where(state_game == n)]\n",
    "    return x, y\n",
    "\n",
    "def manhattan_distance(state: State, goal: np.ndarray, n: int) -> int:\n",
    "\tx1, y1 = get_pos(state.state, n)\n",
    "\tx2, y2 = get_pos(goal, n)\n",
    "\treturn abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "def heuristic(state: State, goal: np.ndarray) -> int:\n",
    "    # return manhattan_distance(state, goal, 0)\n",
    "    return sum([manhattan_distance(state, goal, n) for n in range(1, PUZZLE_DIM**2)]) / 2\n",
    "\n",
    "def astar(state: State, goal: np.ndarray) -> float:\n",
    "    \n",
    "\topen_set = PriorityQueue()\n",
    "\tclosed_set = set()\n",
    "\topen_set.put((0, state))\n",
    "\tcame_from = {}\n",
    "\tg_score = {state: 0}\n",
    "\th_score = {state: heuristic(state, goal)}\n",
    "\n",
    "\twhile not open_set.empty():\n",
    "\t\th, current = open_set.get()\n",
    "\n",
    "\t\tclosed_set.add(current)\n",
    "\t\t\n",
    "\t\t# for i in range(PUZZLE_DIM):\n",
    "\t\t# \tfor j in range(PUZZLE_DIM):\n",
    "\t\t# \t\tplt.text(j, i, current.state[i, j], ha='center', va='center', color='white')\n",
    "\t\t# plt.imshow(current.state, cmap='viridis', interpolation='none')\n",
    "\t\t# plt.colorbar()\n",
    "\t\t# plt.show() if h == 0 else\n",
    "\t\t# plt.clf()\n",
    "\n",
    "\t\tif np.array_equal(current.state, goal):\n",
    "\t\t\tpath = []\n",
    "\t\t\twhile current in came_from:\n",
    "\t\t\t\tpath.append(current)\n",
    "\t\t\t\tcurrent = came_from[current]\n",
    "\t\t\tpath.reverse()\n",
    "\t\t\treturn True, path\n",
    "\n",
    "\t\tfor action in available_actions(current.state):\n",
    "\t\t\tneighbor = do_action(current, action)\n",
    "\t\t\tneighbor_past = g_score[current] + 1\n",
    "\n",
    "\t\t\tif neighbor not in closed_set and (neighbor not in g_score or neighbor_past < g_score[neighbor]):\n",
    "\t\t\t\tcame_from[neighbor] = current\n",
    "\t\t\t\tg_score[neighbor] = neighbor_past\n",
    "\t\t\t\th_score[neighbor] = neighbor_past + heuristic(neighbor, goal)\n",
    "\t\t\t\topen_set.put((h_score[neighbor], neighbor))\n",
    "\n",
    "\treturn False, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = astar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = State(np.random.choice(range(PUZZLE_DIM**2), (PUZZLE_DIM, PUZZLE_DIM), replace=False))\n",
    "goal = State(np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM)))\n",
    "\n",
    "success, path = solver(state, goal)\n",
    "print(success)\n",
    "path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
